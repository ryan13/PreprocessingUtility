{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate a model\n",
    "When our project goes into development stage, it needs to be estimated on several test sets. Furthermore, we also need to determine which measurement metrics for the task. In other words, our first objective is to see how well model cna be **generalized** and second objective is which **measurement metric** will be use. \n",
    "In fact, we often want to compare several models to select the best predictive model. As a result, a final step, **an ad-hoc analysis** will be presented in this notebook to illustrate **how** a comparative decision wil be made with statistic test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Train /test/evaluation** method\n",
    "Split the dataset into two subsets where one subset is used for training, and tuning with test set. finallly evaluating on the last set. We use [Pima Indian diabete dataset](\"https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes\") from UCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age','label']\n",
    "pima = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label\n",
    "\n",
    "    1: diabetes\n",
    "    0: no diabetes\n",
    "\n",
    "pregnant\n",
    "\n",
    "    number of times pregnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X is a matrix, hence we use [] to access the features we want in feature_cols\n",
    "X = pima[['pregnant', 'insulin', 'bmi', 'age']]\n",
    "y = pima.label\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692708333333\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check target class\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of label one \n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing accuracy of a based model\n",
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "# As a target class unbalanced, we illustrate confusion matrix\n",
    "confusion =confusion_matrix(y_test, y_pred_class)\n",
    "print(confusion)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  check the accuracy\n",
    "\n",
    "assert ((TP + TN) / float(TP + TN + FP + FN)) == accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensitivity = TP / float(FN + TP)\n",
    "specificity = TN / (TN + FP)\n",
    "assert metrics.recall_score(y_test, y_pred_class) ==sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision = TP / float(TP + FP)\n",
    "\n",
    "assert precision == precision_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize\n",
    "Which metrics should you focus on?\n",
    "\n",
    "    Choice of metric depends on your business objective\n",
    "        Identify if FP or FN is more important to reduce\n",
    "        Choose metric with relevant variable (FP or FN in the equation)\n",
    "    Spam filter (positive class is \"spam\"):\n",
    "        Optimize for precision or specificity\n",
    "            precision\n",
    "                false positive as variable\n",
    "            specificity\n",
    "                false positive as variable\n",
    "        Because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "    Fraudulent transaction detector (positive class is \"fraud\"):\n",
    "        Optimize for sensitivity\n",
    "            FN as a variable\n",
    "        Because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63247571,  0.36752429],\n",
       "       [ 0.71643656,  0.28356344],\n",
       "       [ 0.71104114,  0.28895886],\n",
       "       [ 0.5858938 ,  0.4141062 ],\n",
       "       [ 0.84103973,  0.15896027],\n",
       "       [ 0.82934844,  0.17065156],\n",
       "       [ 0.50110974,  0.49889026],\n",
       "       [ 0.48658459,  0.51341541],\n",
       "       [ 0.72321388,  0.27678612],\n",
       "       [ 0.32810562,  0.67189438]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)[0:10]\n",
    "# print the first 10 predicted probabilities of class membership\n",
    "logreg.predict_proba(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities for class 1\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x236258fe2b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEdCAYAAADwwTuSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x236241f0fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of predicted probabilities\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# adjust the font size \n",
    "plt.rcParams['font.size'] = 12\n",
    "# 8 bins\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "\n",
    "# x-axis limit from 0 to 1\n",
    "plt.xlim(0,1)\n",
    "plt.title('Histogram of predicted probabilities')\n",
    "plt.xlabel('Predicted probability of diabetes')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We can see from the third bar\n",
    "        About 45% of observations have probability from 0.2 to 0.3\n",
    "        Small number of observations with probability > 0.5\n",
    "        This is below the threshold of 0.5\n",
    "        Most would be predicted \"no diabetes\" in this case\n",
    "    Solution\n",
    "        Decrease the threshold for predicting diabetes\n",
    "            Increase the sensitivity of the classifier\n",
    "                This would increase the number of TP\n",
    "                    More sensitive to positive instances\n",
    "                    Example of metal detector\n",
    "                        Threshold set to set off alarm for large object but not tiny objects\n",
    "                        YES: metal, NO: no metal\n",
    "                        We lower the threshold amount of metal to set it off\n",
    "                        It is now more sensitive to metal\n",
    "                        It will then predict YES more often\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.36752429  0.28356344  0.28895886  0.4141062   0.15896027  0.17065156\n  0.49889026  0.51341541  0.27678612  0.67189438  0.35755557  0.74087965\n  0.36050235  0.23012363  0.42654231  0.19103515  0.45763601  0.1190141\n  0.43928953  0.36961151  0.44187989  0.37611662  0.19816022  0.41677304\n  0.15548281  0.2531671   0.09743077  0.69633712  0.15358309  0.2197836\n  0.43094832  0.34216058  0.22396114  0.38073543  0.13342134  0.38790216\n  0.47049703  0.16204743  0.29548176  0.30918161  0.27299705  0.38816583\n  0.27353443  0.28881041  0.63471914  0.02365251  0.15820648  0.23018375\n  0.3484593   0.27580041  0.33264104  0.24880596  0.74489512  0.39001464\n  0.41625545  0.13575687  0.18895376  0.64777682  0.18922131  0.05685904\n  0.63991547  0.46636382  0.1250972   0.26957602  0.24919104  0.30570396\n  0.46376224  0.20963095  0.42847829  0.40762264  0.20169096  0.27027066\n  0.26255856  0.57238263  0.45467041  0.27716152  0.58001281  0.41599488\n  0.27276101  0.34099223  0.54626578  0.37930723  0.2992205   0.10059169\n  0.32872602  0.45101363  0.16036979  0.4896975   0.63230508  0.40738404\n  0.19794397  0.19698021  0.24463208  0.11147185  0.4158597   0.21561856\n  0.54124529  0.48803602  0.64652767  0.33940658  0.54263427  0.16213824\n  0.3778741   0.11311287  0.34781987  0.34042784  0.1790985   0.21324812\n  0.14710946  0.23014102  0.18404592  0.52224649  0.47099366  0.28884248\n  0.49325079  0.41744473  0.22915008  0.27022911  0.19243924  0.7498713\n  0.46500093  0.6645454   0.42098599  0.53564034  0.16034702  0.1435686\n  0.38142426  0.33827314  0.3630065   0.12842531  0.28333693  0.04005558\n  0.18481139  0.66716947  0.46352874  0.48715682  0.19910794  0.45861651\n  0.23216721  0.18369267  0.26391994  0.37492969  0.12916506  0.41413913\n  0.42460858  0.13832191  0.20781694  0.29477699  0.15825099  0.36016234\n  0.23741449  0.43350689  0.20619881  0.23162338  0.61111541  0.19731009\n  0.80071498  0.17808491  0.36488735  0.78618643  0.44080614  0.36559654\n  0.11760138  0.22843325  0.47865069  0.21320525  0.51498521  0.16122494\n  0.23740119  0.29374391  0.16670048  0.48716526  0.29969894  0.44651043\n  0.50169902  0.29246506  0.61736228  0.41593995  0.25820945  0.1741968\n  0.33519541  0.69606825  0.32454368  0.35730426  0.2336947   0.23738524\n  0.38409318  0.24691412  0.27954552  0.18501174  0.2622362   0.27856926].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-510b479de73e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# it will return 1 for all values above 0.3 and 0 otherwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# results are 2D so we slice out the first column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my_pred_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mbinarize\u001b[1;34m(X, threshold, copy)\u001b[0m\n\u001b[0;32m   1558\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m     \"\"\"\n\u001b[1;32m-> 1560\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1561\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.36752429  0.28356344  0.28895886  0.4141062   0.15896027  0.17065156\n  0.49889026  0.51341541  0.27678612  0.67189438  0.35755557  0.74087965\n  0.36050235  0.23012363  0.42654231  0.19103515  0.45763601  0.1190141\n  0.43928953  0.36961151  0.44187989  0.37611662  0.19816022  0.41677304\n  0.15548281  0.2531671   0.09743077  0.69633712  0.15358309  0.2197836\n  0.43094832  0.34216058  0.22396114  0.38073543  0.13342134  0.38790216\n  0.47049703  0.16204743  0.29548176  0.30918161  0.27299705  0.38816583\n  0.27353443  0.28881041  0.63471914  0.02365251  0.15820648  0.23018375\n  0.3484593   0.27580041  0.33264104  0.24880596  0.74489512  0.39001464\n  0.41625545  0.13575687  0.18895376  0.64777682  0.18922131  0.05685904\n  0.63991547  0.46636382  0.1250972   0.26957602  0.24919104  0.30570396\n  0.46376224  0.20963095  0.42847829  0.40762264  0.20169096  0.27027066\n  0.26255856  0.57238263  0.45467041  0.27716152  0.58001281  0.41599488\n  0.27276101  0.34099223  0.54626578  0.37930723  0.2992205   0.10059169\n  0.32872602  0.45101363  0.16036979  0.4896975   0.63230508  0.40738404\n  0.19794397  0.19698021  0.24463208  0.11147185  0.4158597   0.21561856\n  0.54124529  0.48803602  0.64652767  0.33940658  0.54263427  0.16213824\n  0.3778741   0.11311287  0.34781987  0.34042784  0.1790985   0.21324812\n  0.14710946  0.23014102  0.18404592  0.52224649  0.47099366  0.28884248\n  0.49325079  0.41744473  0.22915008  0.27022911  0.19243924  0.7498713\n  0.46500093  0.6645454   0.42098599  0.53564034  0.16034702  0.1435686\n  0.38142426  0.33827314  0.3630065   0.12842531  0.28333693  0.04005558\n  0.18481139  0.66716947  0.46352874  0.48715682  0.19910794  0.45861651\n  0.23216721  0.18369267  0.26391994  0.37492969  0.12916506  0.41413913\n  0.42460858  0.13832191  0.20781694  0.29477699  0.15825099  0.36016234\n  0.23741449  0.43350689  0.20619881  0.23162338  0.61111541  0.19731009\n  0.80071498  0.17808491  0.36488735  0.78618643  0.44080614  0.36559654\n  0.11760138  0.22843325  0.47865069  0.21320525  0.51498521  0.16122494\n  0.23740119  0.29374391  0.16670048  0.48716526  0.29969894  0.44651043\n  0.50169902  0.29246506  0.61736228  0.41593995  0.25820945  0.1741968\n  0.33519541  0.69606825  0.32454368  0.35730426  0.2336947   0.23738524\n  0.38409318  0.24691412  0.27954552  0.18501174  0.2622362   0.27856926].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "# it will return 1 for all values above 0.3 and 0 otherwise\n",
    "# results are 2D so we slice out the first column\n",
    "y_pred_class = binarize(y_pred_prob, 0.3)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://www.ritchieng.com/machine-learning-evaluate-classification-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how often is the classifier incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-88731c5cf14c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mFP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "assert error == 1 - metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K-fold cross-validation\n",
    "\n",
    "    Systematically create \"K\" train/test splits and average the results together\n",
    "    Even better estimate of out-of-sample performanc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "In the context of binary classification, examples are either positive or negative.   \n",
    "**TP** (True Positive) =  Test says “A” while True is \"A\"; **FN** (False Negative)=  Test says \"Not A\" while it is \"A\".\n",
    "**FP** (Falso positive)=  Test says \"A\" while it is not \"A\"; **TN** (True negative)=  Test says \"not A\" while it is not \"A\"\n",
    "\n",
    "\n",
    " > The recall addresses the question: \"Given a positive example, will the classifier detect it ?\"    \n",
    " > The precision addresses the question: \"Given a positive prediction from the classifier, how likely is it to be correct ?\"\n",
    " \n",
    "Recall = TP/(TP + FN) whereas precision = TP/(TP+FP).   \n",
    "Eg.1: Assuming we create a detect videos that is safe for kid, our model may decide to keep only a good one (low recall) or higher TP by keeping only a safe one (high precision) **Rather than** higher recall but leta a few bad videos go through.\n",
    "E.g 2: A prodictive model to detect shopliters on surveillance video: we want all shoplifter caught by raising higer recall and allow lower precision. Since precision increases, recall decreases, this is known as precision-recall trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## When threshold comes into a pictures\n",
    "Threshold can be used to changed precision/ recall. To explain, we consider an example from Handon- ML and Tensor page 69\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
